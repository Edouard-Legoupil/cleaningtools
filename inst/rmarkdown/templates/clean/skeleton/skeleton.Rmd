---
title: "Data cleaning Check and Review report"
date: "`r format(Sys.Date(),  '%d %B %Y')`"
output: 
  html_document: 
    toc: yes
    toc_depth: 2
params:
  datafolder: "inst" # "data-raw"
  form: "form.xlsx" ## name of the xlsform
  rawwl: "data.xlsx" ## Name of the  raw data file
  lower_treshold:  15  ## Mininimum survey duration in minutes
  higher_threshold: 100 ## Maximum survey duration in minutes
  start_column: "X.U.FEFF.start"  ## Specific variable where the start timestamp is recorded
  end_column: "end" ## Specific variable where the end timestamp is recorded
  sm_separator: "." ## seprator for select multiple parameters 
  clean_data_consent_column: "consent_remote"  ## varaible for consent
  clean_data_consent_yes_value: "yes"     ## mddality for accepted conent
  cleannl: "clean_data.xlsx"  ## Where does clean data go --
  logical_check_list: "logical_check_list.xlsx" ## file where logicial checks are being defined. Set to NULL if not used 
  loggl_torev: "cleaning_log_to_rev.xlsx"  ## Where the cleaning log is saved 
  loggl: "cleaning_log.xlsx"  ## Where the cleaning log is reloaded after manual edit
  addlog1: "enumerator_num"  ## first variable from dataset to add - for instance enumerator identifiers 
  addlog2:  "X.U.FEFF.start"  ## second variable from dataset to add - for instance date 
  sampling_frame: "sampling_frame.xlsx"  ## Definition of the sampling frame. Set to NULL if not used  
  sample_frame_strata_column: "Neighbourhood" ## Key variable to join sampling frame if any
  sample_frame_target_survey_column: "Total.no.of.HH" ## target # of records
  clean_data_strata_column: "neighbourhood"  ## Key variable to join with sampling frame if any
  check_for_duplicates: TRUE
  check_for_soft_duplicates: TRUE  ## If false idnk value will not be used..
  idnk_value: "idnk"
  check_for_PII: TRUE
  check_for_time: TRUE
  check_for_shortest_path: TRUE
  check_for_outliers: TRUE
  check_for_logical: TRUE
  check_for_others: TRUE
  check_for_NA_values: TRUE
  check_for_deletions: TRUE
  check_for_etc: TRUE
  review_the_cleaning_log: TRUE
  review_the_others_recoding: FALSE
  review_the_sampling_frame: FALSE
  ridl: "test" ## RIDL id so that cleaning log, cleaned data, this report and notebook can be recorded
  publish: FALSE ## Set to yes once ready to archive your work
---  


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, 
                      message = FALSE,
                      warning = FALSE)
library(tidyverse)
library(cleaningtools)
```
 
# Introduction

This review is separated into two parts *Data checks* and *Cleaning log*: 

 * The first part will performed different check on the dataset, depending on the information available 
(time, outliers, shortest path, etc.).  
- The second part will look at how the cleaning was performed. It will first look if the values from the
cleaning log are correctly changed in the clean data, and then it will look at differences between the 
raw data and clean data and see if anything was not logged into the cleaning log.  

```{r reading config file}
# Datasets and logs
raww <- readxl::read_excel(here::here(params$datafolder ,params$rawwl))
uuid_raww <- detect_uuid(raww)
## fix for export that includes full name - with group included
#names(raww) <- stringr::str_replace_all(names(raww) , "/", ".")

# possible fix for start&end
# raww[[params$start_column]] = lubridate::ymd_hms(raww[[params$start_column]])
# raww[[params$end_column]] = lubridate::ymd_hms(raww[[params$end_column]])
# cat(paste0("start class is ", 
#            class(raww[[params$start_column]]), 
#            " and end class is ",
#            class(raww[[params$end_column]])  ))


list_log <- raww
review_log <- list()

survey <- readxl::read_excel(here::here(params$datafolder ,params$form), sheet = "survey")
## fix for export that includes full name - with group included
#survey$name_or <- survey$name
#survey$name <- survey$fullname

choices <- readxl::read_excel(here::here(params$datafolder ,params$form), sheet = "choices") 
```




```{r reading_logicalCheck}
# Logical checks list
# logical_check_list <- data.frame(
#   check_id = c("check_exp", "check_2"), 
#   description = c("primary_livelihood is rented but expenses less than 500000", 
# "acces water and tank emptied"), 
# check_to_perform = c("primary_livelihood == \"employment\" & tot_expenses < 500000", 
#                      "access_water_enough == \"totally_insufficient\" & tank_emptied == \"about_half\""),
# columns_to_clean = c("primary_livelihood, tot_expenses",
#                      "access_water_enough, tank_emptied"
# ))

if( ! (is.null(params$logical_check_list))){
logical_check_list <- readxl::read_excel(here::here(params$datafolder, params$logical_check_list))

# Logical checks list information - those are stanard one
check_id_column <- "check_id"
description_column <-  "description"
check_to_perform_column <-  "check_to_perform"
columns_to_clean_column <- "columns_to_clean"
check_for_logical <- TRUE
  
} else {  check_for_logical <- FALSE }

```


```{r reading_sample}
# Sampling frame

if( ! (is.null(params$sampling_frame))){
#sampling_frame <- cleaningtools::cleaningtools_sample_frame
sampling_frame <- readxl::read_excel(here::here(params$datafolder, params$sampling_frame))
# sampling frame information
sample_frame_strata_column <-  params$sample_frame_strata_column #"Neighbourhood"
sample_frame_target_survey_column <-  params$sample_frame_target_survey_column # "Total.no.of.HH"
clean_data_strata_column  <-  params$clean_data_strata_column #"neighbourhood"

} else {  check_for_sampling <- FALSE }
```


```{r reading_consent}
clean_data_consent_column  <-  params$clean_data_consent_column #"consent_remote"
clean_data_consent_yes_value  <- params$clean_data_consent_yes_value # "yes"

```


```{r load_parameters}
#| message: false
#| warning: false
# tests to include  TRUE / FALSE
check_for_duplicates <-params$check_for_duplicates # TRUE
check_for_soft_duplicates <- params$check_for_soft_duplicates #TRUE
check_for_PII <- params$check_for_PII #TRUE
check_for_time <- params$check_for_time #TRUE
check_for_shortest_path <- params$check_for_shortest_path #TRUE
check_for_outliers <- params$check_for_outliers #TRUE
check_for_others <- params$check_for_others #TRUE
check_for_NA_values <- params$check_for_NA_values #TRUE
check_for_deletions <- params$check_for_deletions #TRUE
check_for_etc <- params$check_for_etc #TRUE
```


```{r load datasets and parameters}
review_the_cleaning_log <- params$review_the_cleaning_log #TRUE
review_the_others_recoding <- params$review_the_others_recoding #TRUE
review_the_sampling_frame <- params$review_the_sampling_frame #TRUE
```



```{r}
# # modifying the cleaning log to create xx
# if (!change_type_column %in% names(logg)) {
#   logg <- logg |>
#     dplyr::mutate(!!dplyr::sym(change_type_column) := dplyr::case_when(
#       is.na(!!dplyr::sym(new_value_logg)) | !!(dplyr::sym(new_value_logg) == "NA") ~ "blank_response",
#       !!dplyr::sym(new_value_logg) == !!dplyr::sym(old_value_logg) ~ "no_action",
#       !!dplyr::sym(new_value_logg) != !!dplyr::sym(old_value_logg) ~ "change_response",
#       TRUE ~ "cannot identify the action"
#     ))
# }

# logg[logg == "NA"] <- NA_character_

```


# Performing Systematic Data checks

## Checks for duplicates 

```{r check duplicates} 
if (check_for_duplicates) { 
  list_log <- check_duplicate(dataset = list_log, 
                              uuid_column = uuid_raww)

  print_log(list_log$duplicate_log, 
            "No duplicates found")
} else {
  
paste("Check not requested ")  
}
```
 

## Checks for soft duplicates

```{r check soft duplicates}
if (check_for_soft_duplicates) {
  list_log <- check_soft_duplicates(
    dataset = list_log,
    kobo_survey = survey,
    uuid_column = uuid_raww,
    idnk_value = params$idnk_value, #"idnk",
    sm_separator = params$sm_separator,
    threshold = 7
  )
  list_log$soft_duplicate_log <- list_log$soft_duplicate_log

  print_log(list_log$soft_duplicate_log, "No soft duplicates found")
} else {
  
paste("Check not requested ")  
}
```

## Checks for PII

*NOTE*:   
- Only looks for some keywords in the names of the dataset.  
- It does not check the value in those columns

```{r check pii}
if (check_for_PII) {
  list_log <- list_log |>
    check_pii(uuid_column = uuid_raww)
  
  print_log(list_log$potential_PII, "No sensitive columns found")
  
  raww %>% 
    select(any_of(list_log$potential_PII$question)) %>% 
    lapply(unique)
}  else {
  
paste("Check not requested ")  
}
```

```{r}
  raww %>% 
    select(any_of(list_log$potential_PII$question)) %>% 
    lapply(unique)
```

## Check for time

```{r check time}
#| warning: false
lower_treshold <- params$lower_treshold #15
higher_threshold <- params$higher_threshold #100

if (check_for_time) {
  list_log$checked_dataset <- list_log$checked_dataset |>
    add_duration(uuid_column  = uuid_raww, 
                 start_column = params$start_column, #"X.U.FEFF.start", 
                 end_column = params$end_column) # "end")
  list_log <- list_log |>
    check_duration(
      column_to_check = "duration",
      uuid_column  = uuid_raww,
      lower_bound = lower_treshold,
      higher_bound = higher_threshold
    )

  print_log(list_log$duration_log, "No time sensitive interviews found")
} else {
  
paste("Check not requested ")  
}
```

**Note**:  
- Check time for lower threshold as `r lower_treshold` minutes and higher threshold as `r higher_threshold` minutes.

## Check for shortest path

```{r check shortest path}
# take only select and integer to look at NA (removing text, dummies, notes, etc.)
if (check_for_shortest_path) {
  if (exists("questions")) {
    list_log$checked_dataset <- list_log$checked_dataset |>
      add_percentage_missing(
        kobo_survey = survey,
        type_to_include = c(
          "integer",
          # "date",
          "text",
          "select_one",
          "select_multiple"
        )
      )
  } else {
    list_log$checked_dataset <- list_log$checked_dataset |>
      add_percentage_missing()
  }
  list_log <- list_log |>
    check_percentage_missing(uuid_column = uuid_raww)
  print_log(list_log$percentage_missing_log, "No survey with outstanding blanks found")
} else {
  
paste("Check not requested ")  
}
```

## Check for outliers

```{r check outliers, message=FALSE, warning=FALSE}
if (check_for_outliers) {
  list_log <- cleaningtools::check_outliers(
    dataset = list_log,
    uuid_column  = uuid_raww,
    kobo_survey = survey,
    kobo_choices = choices,
    sm_separator = params$sm_separator
  )
  
  print_log(list_log$potential_outliers, "No outlier found")
  
} else {
  
paste("Check not requested ")  
}
```
 

## Logical check 

```{r, warning = F, message = F}
if (check_for_logical) {
  list_log <- list_log |>
    check_logical_with_list(
      uuid_column  = uuid_raww,
      list_of_check = logical_check_list, 
      check_id_column = check_id_column, 
      description_column = description_column,
      check_to_perform_column = check_to_perform_column,
      columns_to_clean_column = columns_to_clean_column
    )

  list_log$checked_dataset %>% 
    summarise(across(.cols = any_of(logical_check_list[[check_id_column]]), .fns = ~mean(.x, na.rm = T) *100)) %>% 
    pivot_longer(cols = everything()) %>% 
    arrange(desc(value)) %>% 
    rename(logical_checks = name, 
           percent_of_dataset = value)

  print_log(list_log$logical_all, "No logical checks found")
}  else {
  
paste("Check not requested ")  
}
```

 

## Other and translation

If a KOBO tool is provided, it will check all text columns. If there is no KOBO tools, it will check columns ending with "_oth, _other,_autre".

```{r check other}
if (check_for_others) {
  if (exists("survey")) {
    text_oth <- survey |>
      dplyr::filter(type == "text", name %in% names(raww)) |>
      dplyr::pull(name)
  } else {
    text_oth <- grep(pattern = "_oth|_other|_autre", x = names(raww), value = T)
  }
  list_log <- list_log |>
    check_others(
      uuid_column = uuid_raww,
      columns_to_check = text_oth
    )
  
  paste0("All the values from text questions")
  list_log$other_log |>
    dplyr::arrange(question, old_value) |>
    knit_big_table()
  
  paste0("How many interviews per text question \n")
  list_log$other_log |>
    dplyr::group_by(question) |>
    dplyr::tally(sort = T) |>
    knit_big_table()
  
  paste0("Values which are identical. ")
  
  list_log$other_log |>
    dplyr::group_by(old_value) |>
    dplyr::tally(sort = T) |>
    knit_big_table()
  
  
} else {
  
paste("Check not requested ")  
}
```

   

## Check for NAs values

```{r check for values}
if (check_for_NA_values) {
  
  values_to_check <- c(99, 999, 999, 88, 888, 888)

  paste0("This checks looks for the following values: ", values_to_check, "\n")

  
  list_log <- list_log |>
    check_value( 
      uuid_column = uuid_raww,
      values_to_look = values_to_check
    )

  # fix for check not adding issue
  list_log$flaged_value$issue <- "Possible value to be changed to NA"

  print_log(list_log$flaged_value, "No values found")
} else {
  
paste("Check not requested ")  
}
```



## Creating Cleaning log file to be manually edited...

```{r}
list_log2 <- list_log |>
  create_combined_log() 

list_log3 <- list_log2 |> 
  add_info_to_cleaning_log(dataset_uuid_column =  uuid_raww,
                           information_to_add = c(params$addlog1,
                                                  params$addlog2) )

create_xlsx_cleaning_log(
    write_list = list_log3, 
    kobo_survey = survey,
    kobo_choices = choices,
    use_dropdown = TRUE,
    output_path = here::here(params$datafolder , params$loggl_torev)
  ) 
```
The file  `r paste0(params$loggl_to_rev)`  is manually edited and saved as `r paste0(params$loggl)`. 

The change_response column can only take the following values:

|value|Definition|
|-----|----------|
|`change_response`|Change the response to new.value|
|`blank_response`|Remove and NA the response|
|`remove_survey`|Delete the survey|
|`no_action`|No action to take|



``` {r, eval=T, message=TRUE}
# After obtaining both the cleaning log and dataset, it is considered good practice to utilize the review_cleaning_log() function to ensure the consistency between the cleaning log and the dataset. 

#It is highly recommended to perform this check on a daily basis, enabling you to promptly identify any issues right from the outset.

clogg <- readxl::read_excel(here::here(params$datafolder ,params$loggl),
                           sheet = "cleaning_log")
table(clogg$change_type, useNA = "ifany")

## Remove the specific case of PPI identified where 
clogg <- clogg |>
         dplyr::filter( uuid != "all")

# review_cleaning_log(
#   raw_dataset = raww,
#   raw_data_uuid_column = uuid_raww,
#   cleaning_log = clogg,
#   cleaning_log_change_type_column = "change_type",
#   change_response_value = "change_response",
#   cleaning_log_question_column = "question",
#   cleaning_log_uuid_column = "uuid",
#   cleaning_log_new_value_column = "new_value"
# )
```


``` {r, eval=T, message=TRUE}
#Once you have a perfect cleaning log and the raw dataset, you can create clean data by applying`create_clean_data()` function. 
cleann <- cleaningtools::create_clean_data(
  raw_dataset = raww,
  raw_data_uuid_column = uuid_raww,
  cleaning_log = clogg,
  cleaning_log_change_type_column = "change_type",
  change_response_value = "change_response",
  NA_response_value = "blank_response",
  no_change_value = "no_action",
  remove_survey_value = "remove_survey",
  cleaning_log_question_column = "question",
  cleaning_log_uuid_column = "uuid",
  cleaning_log_new_value_column = "new_value"
)
 
#`recreate_parent_column()` recreates the concerted columns for select multiple questions
 
# cleann <- cleaningtools::recreate_parent_column(dataset = cleann,
#                                       uuid_column =  uuid_raww,
#                                       sm_separator = ".")  

## and now save the cleaned version of the data...
openxlsx::write.xlsx(cleann , 
                       here::here(params$datafolder ,params$cleann), 
                       overwrite = TRUE)
```

# Review of the cleaning decision based on the log

```{r reading_cleaning}
#cleann <- cleaningtools::cleaningtools_clean_data
cleann <- readxl::read_excel(here::here(params$datafolder ,params$cleann))
uuid_cleann <- detect_uuid(cleann)

#logg  - cleaning log
logg <- readxl::read_excel(here::here(params$datafolder ,params$loggl),
                           sheet = "cleaning_log") |>
  dplyr::filter(change_type != "remove_survey")
uuid_logg <- detect_uuid(logg)

#dell  - deletion log
dell <- readxl::read_excel(here::here(params$datafolder ,params$loggl),
                           sheet = "cleaning_log") |>
  dplyr::filter(change_type == "remove_survey")
uuid_dell <- detect_uuid(dell)

```


Verify the number of uuids that are common in clean dataset and deletion log.

```{r check deletions}
number_cleann_in_dell <- "Check not performed"
number_dell_in_cleann <- "Check not performed"
number_difference_raw_clean_del <- "Check not performed"

if (check_for_deletions) {
  data.frame(
    n_raw = nrow(raww),
    n_clean = nrow(cleann),
    n_deleted = nrow(dell),
    sum_clean_del = nrow(cleann) + nrow(dell)
  )

  number_cleann_in_dell <- cleann[[uuid_cleann]] %in% dell[[uuid_dell]] |> sum()
  number_dell_in_cleann <- dell[[uuid_dell]] %in% cleann[[uuid_cleann]] |> sum()
  number_difference_raw_clean_del <- abs(nrow(raww) - nrow(cleann) - nrow(dell))
}
```

 * Difference between of rows between the raw, clean and deletion log:  `r number_difference_raw_clean_del`  
 
 * Number of uuid of clean in deleted : `r number_cleann_in_dell`  
 
 * Number of uuid of deleted in clean : `r number_dell_in_cleann`  
 
## Review the cleaning log 

```{r review cleaning}

if (review_the_cleaning_log) {
  review_log[["review_cleaning"]] <- review_cleaning(
    raw_dataset = raww,
    raw_dataset_uuid_column = uuid_raww,
    clean_dataset = cleann,
    clean_dataset_uuid_column = uuid_cleann,
    cleaning_log = logg,
    cleaning_log_uuid_column = uuid_logg,
    cleaning_log_change_type_column = "change_type",
    cleaning_log_question_column = "question",
    cleaning_log_new_value_column = "new_value",
    cleaning_log_old_value_column = "old_value",
    cleaning_log_added_survey_value = "added_survey",
    cleaning_log_no_change_value = "no_action",
    deletion_log = dell,
    deletion_log_uuid_column = uuid_dell,
    check_for_deletion_log = T
  )
  
  review_log[["review_cleaning"]] |>
    dplyr::group_by(comment) |>
    dplyr::tally()
} else {
  
paste("Review not requested ")  
}
```



## Review of others re-coding

```{r Review of others re-coding}
if (review_the_others_recoding) {
   
  
  review_log[["review_the_others_log"]] <- review_others(
            dataset = cleann,
            uuid_column = uuid_cleann,
            kobo_survey = survey,
            sm_separator = params$sm_separator
          )
  
  review_log[["review_the_others_log"]]  |>
    dplyr::group_by(issue) |>
    dplyr::tally()
  
} else {
  
paste("Review not requested ")  
}

# Error in `dplyr::select()` at cleaningtools_ed/R/create_logic_for_other.R:172:2:
# ! Can't subset columns that don't exist.
# ✖ Column `logic` doesn't exist.
# Backtrace:
#  1. cleaningtools::review_others(...)
#  2. cleaningtools::create_logic_for_other(...)
#       at cleaningtools_ed/R/review_others.R:56:2
#  4. dplyr:::select.data.frame(...)

```

## Review of the data and sampling frame 

```{r Review of the data and sampling frame}
if (review_the_sampling_frame) {
    
  review_log[["review_sf"]]   <- review_sample_frame_with_dataset(
    sample_frame = sampling_frame,
    sampling_frame_strata_column = sample_frame_strata_column,
    sampling_frame_target_survey_column = sample_frame_target_survey_column,
    clean_dataset = cleann,
    clean_dataset_strata_column = clean_data_strata_column,
    consent_column = clean_data_consent_column,
    consent_yes_value = clean_data_consent_yes_value
  )

 review_log[["review_sf"]]
} else {
  
paste("Review not requested ")  
}
```

 

# Conclusion

Two files have been created:

 * A new cleaned version of your dataset
 
 * A standardized cleaning log that records all the actions you made on the raw data

```{r wrap-up}
all_logs <- list(cleaning_log = logg) |>
  append(review_log)

openxlsx2::write_xlsx(all_logs,
                      file = here::here(params$datafolder ,"review_cleaning_log.xlsx" ), #
                     #params$loggl) ,
                      overwrite = T,
                      na.strings = "")

## Publish to RIDL if set so...
## Publish to RIDL if set so...
if( params$publish == "yes"){
  namethisfile = basename(rstudioapi::getSourceEditorContext()$path )  
  add_ridl(ridl = params$ridl,
            datafolder = params$datafolder,
            cleanned_data = params$cleann,
            cleaning_log = params$loggl,
            namethisfile =  namethisfile  ) }


```
 
